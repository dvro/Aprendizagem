% !TEX encoding = ISO-8859-1
\chapter{Técnicas Avaliadas}
\label{ch:ch2}

\section{Contexto e Histórico}
\label{sec:contexto}

Esta sessão abordará sistemas de reconhecimento de padrões e classificadores com aprendizagem baseadas em instâncias.

\subsection{Sistemas de Reconhecimento de Padrões}
\label{subsec:sistemas}

No final dos anos 50, surgiram os primeiros trabalhos de aprendizagem de máquina. De uma forma geral, elas consistiam em dar ao computador a habilidade de reconhecer formas. A partir daí, surgiram diversos problemas onde a aprendizagem de máquina atuava. 

Existem três problemas gerais que a aprendizagem de máquina tenta resolver. Um deles é o problema do agrupamento, que consiste em agrupar dados de acordo com suas características, de forma que seja possível extrair informação útil destes agrupamentos. Um outro problema é a discriminação, que basicamente é achar uma forma de reconhecer um conceito, dado um conjunto de conceitos exemplos. O terceiro e último problema é o da generalização, que é o problema de como reduzir uma regra de classificação, tornando-a mais abrangente e menos custosa.

Reconhecimento de padrões ataca principalmente o problema da discriminação, tendo por objetivo classificar padrões, discriminando-os entre duas ou mais classes. A classificação pode ser feita com padrões pertencentes a qualquer domínio, como reconhecimento de digitais, gestos, escrita, fala, entre outros.

\section{Classificadores}
\label{sec:classificadores}

Todo sistema de reconhecimento de padrões utiliza um classificador para discriminar os padrões de teste. A eficiência de um classificador é medida pela taxa de acerto média, pela variância, e pelo seu custo computacional. Um classificador de aprendizagem baseada em instâncias muito utilizado é o \textit{K-Nearest Neighbor}, KNN [\cite{knnrule:1969}]. 

\subsection{K-Nearest Neighbor}
\label{subsec:knn}

O KNN é muito usado por ser um método de aprendizagem supervisionado simples, e por possuir uma taxa de acerto relativamente alta. O conceito básico consiste em: Dado um padrão $x$ a ser classificado e um conjunto de padrões conhecidos $T$, obter as classes dos $K$ elementos de $T$ mais próximos de $x$. A classe que obtiver maior ocorrência, ou peso, será a classe de $x$. Pode-se dizer que o KNN utiliza uma abordagem \textit{"Dize-me com quem andas, e direi quem és."}. O algoritmo esta descrito em Algorithm \ref{alg:knn}.

\begin{algorithm}[H]
\caption{KNN}
\label{alg:knn}
\begin{algorithmic}[1]
\REQUIRE {$K$: um número}
\REQUIRE {$T$: conjunto de treinamento}
\REQUIRE {$x$: elemento para ser classificado}
\REQUIRE {$L$: uma lista}
\FORALL {$t_i$ $\in$ $T$}
\STATE  $d_i$ = $distance(t_i, x)$
\STATE  adicione $(d_i, Classe(t_i))$ em $L$
\ENDFOR
\STATE $Ordene(L)$ de acordo com as distâncias
\STATE obtenha os $K$ primeiros elementos de $L$
\RETURN a classe de maior ocorrência, ou peso, entre os $K$
\end{algorithmic}
\end{algorithm}


\subsection{Janela de Parzen}
\subsection{MLE}
\subsection{EM}
\subsection{Combinação de Classificadores}

\section{Agrupamento}
\subsection{K-Means}



